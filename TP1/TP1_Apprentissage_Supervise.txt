TP1 Apprentissage supervisé

Exercice 1 : Manipulation de la base de données
1.	Commandes basiques
print(mnist) : affiche tous les attributs du jeu de données
print (mnist.data) : affiche le tableau contenant les données: une ligne = une instance = représentation des valeurs des pixels d'une image et une colonne = valeur d'un pixel a une certaine position sur toutes les images
print (mnist.target) : affiche les étiquettes/labels des instances, ici les digits représentés par les images
len(mnist.data) : affiche le nombre de lignes du tableau de données = nombre d'instances/d’images dans le jeu de données
help(len) : affiche la documentation de la fonction len
print (mnist.data.shape) : affiche la forme de la matrice de données c’est-à-dire le nombre de lignes et de colonnes du tableau de données = (nombre d'instances/images, nombre d'attributs ici nombre de pixels par image)
print (mnist.target.shape) : affiche la forme du tableau des étiquettes/labels ici le nombre d'instances/images
mnist.data[0] : affiche le tableau représentant la valeur des pixels de la première instance/image
mnist.data[0][1] : affiche la valeur du second pixel de la première image
mnist.data[:,1] : affiche la valeur du second pixel de toutes les images = la seconde colonne du tableau de données
mnist.data[:100] : affiche les 100 premières instances/images
2.	Visualisation des données
Pour visualiser les données sous forme d’images (et pas comme tableau de pixel), on modifie le tableau de données (images = mnist.data.reshape((-1, 28, 28))) en conservant les 70000 lignes (grâce au -1) et transforme les vecteurs (lignes=vecteurs de pixel représentant une image) de 784 valeurs (images) en matrices de 28 lignes * 28 colonnes représentant les valeurs des pixels des images. Cela permet ensuite d’afficher ces matrices de 28*28 pixels sous forme d’image en nuance de gris (plt.imshow(image,cmap=plt.cm.gray_r,interpolation="nearest")). On peut afficher la classe d’une image (la première par exemple) avec print(mnist.target[0]).
Exercice 2 : la méthode des K-NN
On commence par charger la base de données MNIST et prendre un échantillon de taille 5000 pour commencer (sur les 70000 disponibles). On divise cet échantillon en prenant 80% pour l’apprentissage et 20% pour le test. On commence par choisir k = 10 comme nombre de voisin et après avoir entrainé le classifieur k-nn, on obtient un score de 91,9% sur la base de test. Sur nos données d’apprentissage, le taux d’erreur est de 6,57%. Il est normal que ce taux soit faible car le classifieur a été entrainé sur ces données et doit donc y correspondre au maximum. Cependant, si ce taux est très proche de 0, cela pourrait indiquer un sur-apprentissage car le classifieur serait trop spécifique au jeu de données d’entrainement.
Pour trouver le nombre de voisin k optimal pour ce jeu de données, nous calculons les scores obtenus pour des k différents en prenant 80% des données pour l’entrainement. A chaque k, nous récupérons le score obtenu pour plusieurs combinaisons de données d’apprentissage et de test et en faisons la moyenne. Ainsi, nous réduisons l’impact du choix des données d’apprentissage et de test sur le score, ce qui permet d’isoler l’influence du nombre de voisin k sur le score. Nous obtenons le score le plus élevé pour k=3.
Nous étudions ensuite l’influence du pourcentage utilisé pour la séparation entre données d’apprentissage et de test sur le score. Pour ce faire, nous calculons de score pour des pourcentages allant de 70% à 90% avec des pas de 5%. Nous obtenons le meilleur score en prenant 90% des données pour l’apprentissage, cependant cette valeur peut varier selon les données prises dans l’échantillon et la façon dont elles sont séparées. (on pourrait faire plusieurs séparations pour un même pourcentage pour limiter l’influence des données elles-mêmes sur le score.)
La taille de l’échantillon de données impacte aussi le score. Nous visualisons cette influence en faisant varier la taille de l’échantillon entre 2000 et 57000 par pas de 5000. Le score s’améliore lorsque la taille de l’échantillon augmente ce qui peut s’expliquer par le fait que plus il y a de données dans l’échantillon (plus il y en a dans la base d’apprentissage), plus le classifieur dispose d’informations, de précisions sur les données et plus il sera adapté aux données (en évitant l’effet de sur-apprentissage évoqué précédemment). Il faut cependant prendre en considération l’augmentation importante du temps d’apprentissage et de prédiction lié à l’augmentation de la taille de l’échantillon. Il faut donc décider d’un compromis entre temps d’exécution et score élevé. Nous avons choisi une taille de 32000 pour l’échantillon car le score obtenu est proche de l’optimum (96,8% pour un optimum de 97,7%) avec un temps d’exécution bien plus faible (140 au lieu de 442).
Le type de distance utilisé influence aussi le score, c’est pourquoi nous avons calculé le score pour la distance de Manhattan (p=1), la distance euclidienne (p=2) et la distance de Minkowski (avec un paramètre de 3 puis de 4).
Pour finir, nous comparons l’usage de la parallélisation pour réduire le temps de prédiction.
